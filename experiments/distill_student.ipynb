{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载并初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of student model is: 2.92M\n",
      "The number of parameters of teacher model is: 87.85M\n"
     ]
    }
   ],
   "source": [
    "import sys, json\n",
    "with open('config.json') as f:\n",
    "    args = json.load(f)\n",
    "sys.path.append('..')\n",
    "PATH = '../RKDSC-github/results/'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm \n",
    "from models import GenTeacher, GenStudentCNN, GenClassifier\n",
    "from models.model import AttentionAutoEncoder\n",
    "from utils import save_model, test_on_val\n",
    "from utils.dataset import get_datasets\n",
    "from utils.channels import Channels\n",
    "\n",
    "device = args[\"global\"][\"device\"]\n",
    "teacher_model_name = args[\"model\"][\"teacher_model_name\"]\n",
    "student = GenStudentCNN(device)\n",
    "teacher = GenTeacher(teacher_model_name, device)\n",
    "\n",
    "print(f\"The number of parameters of student model is: {sum(p.numel() for p in student.parameters()) / 1e6:.2f}M\" )\n",
    "print(f\"The number of parameters of teacher model is: {sum(p.numel() for p in teacher.parameters()) / 1e6:.2f}M\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_datasets(args[\"data\"][\"path\"], args[\"data\"][\"batch_size\"], args[\"data\"][\"dataset_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 蒸馏学生模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea1f86afe8c43ccb9c54b3e0a98e955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Distillation:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d839eb4afe4473b3673381fd392cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher.eval()\n",
    "student.train()\n",
    "MIN_LOSS = 5\n",
    "optimizer_stu = torch.optim.Adam(student.parameters(), lr=args[\"distillation\"][\"learning_rate\"])\n",
    "criterion_KD = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer_stu, step_size=args[\"distillation\"][\"epochs\"] // 2, gamma=0.1)\n",
    "\n",
    "epoch_bar = tqdm(range(args[\"distillation\"][\"epochs\"]), desc=\"Distillation\")\n",
    "for epoch in epoch_bar:\n",
    "    batch_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\", leave=False)\n",
    "    for i, (data, _) in batch_bar:\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer_stu.zero_grad()\n",
    "        teacher_output = teacher(data)\n",
    "        student_output = student(data)\n",
    "\n",
    "        loss_KD = criterion_KD(student_output, teacher_output)\n",
    "        batch_bar.set_postfix({'KD Loss': loss_KD.item(), 'LR': scheduler.get_last_lr()[0]})\n",
    "\n",
    "        loss_KD.backward()\n",
    "        optimizer_stu.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if loss_KD.item() < MIN_LOSS:\n",
    "        MIN_LOSS = loss_KD.item()\n",
    "        save_model(student, args[\"distillation\"][\"model_saved_path\"] + 'source_encoder_kd.pt')\n",
    "\n",
    "    epoch_bar.set_postfix({'KD Loss': loss_KD.item(), 'LR': scheduler.get_last_lr()[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练学生模型对应的分类网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm  # 或者 from tqdm.auto import tqdm\n",
    "\n",
    "classifier = GenClassifier(512, 100, [], device)\n",
    "classifier.train()\n",
    "student.eval()\n",
    "\n",
    "optimizer_cla = torch.optim.Adam(classifier.parameters(), lr=args[\"classification\"][\"learning_rate\"])\n",
    "criterion_CE = nn.CrossEntropyLoss()\n",
    "\n",
    "# 外层进度条：显示 epoch 进度\n",
    "for epoch in tqdm(range(args[\"classification\"][\"epochs\"]), desc=\"Epoch\", ncols=150):\n",
    "    # 内层进度条：显示当前 epoch 内 batch 的进度，leave=False 表示本 epoch 结束后该进度条自动清除\n",
    "    with tqdm(enumerate(train_loader),\n",
    "              total=len(train_loader),\n",
    "              desc=f\"Epoch {epoch+1} Batch\",\n",
    "              ncols=150,\n",
    "              leave=False) as batch_bar:\n",
    "        for i, (data, target) in batch_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer_cla.zero_grad()\n",
    "            student_output = student(data)\n",
    "            output = classifier(student_output)\n",
    "\n",
    "            loss_CE = criterion_CE(output, target)\n",
    "            acc = (output.argmax(dim=1) == target).float().mean()\n",
    "            # 更新内层进度条的状态信息\n",
    "            batch_bar.set_postfix({'CE Loss': loss_CE.item(), 'Accuracy': acc.item()})\n",
    "\n",
    "            loss_CE.backward()\n",
    "            optimizer_cla.step()\n",
    "\n",
    "    # 每个 epoch 结束后保存模型\n",
    "    save_model(classifier, args[\"distillation\"][\"model_saved_path\"] + 'source_decoder_kd.pt')\n",
    "\n",
    "# 测试分类器效果\n",
    "acc_test = test_on_val(student, classifier, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "atten_ae = AttentionAutoEncoder(512, 2).to(device)\n",
    "channel = Channels(device)\n",
    "optimizer_cla = torch.optim.Adam(classifier.parameters(), lr=5e-5)\n",
    "optimizer_ae = torch.optim.Adam(atten_ae.parameters(), lr=5e-5)\n",
    "optimizer_stu = torch.optim.Adam(student.parameters(), lr=5e-4)\n",
    "\n",
    "criterion_AE = torch.nn.MSELoss()\n",
    "criterion_CE = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "student.train()\n",
    "classifier.train()\n",
    "atten_ae.train()\n",
    "\n",
    "TRAIN_SNR_LIST = [-5, -2, 0, 5, 10, 15, 20]\n",
    "\n",
    "for epoch, snr in enumerate(tqdm(TRAIN_SNR_LIST, desc=\"Epoch\", ncols=120)):\n",
    "    batch_bar = tqdm(train_loader,\n",
    "                     leave=False,\n",
    "                     ncols=120,\n",
    "                     desc=f\"Epoch {epoch+1} Training on SNR={snr}\")\n",
    "    \n",
    "    for i, (images, labels) in enumerate(batch_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer_cla.zero_grad()\n",
    "        optimizer_ae.zero_grad()\n",
    "        optimizer_stu.zero_grad()\n",
    "\n",
    "        features_stu = student(images)\n",
    "        features_tea = teacher(images)\n",
    "\n",
    "        latten_ae = atten_ae.encoder(features_stu)\n",
    "        latten_ae = channel.AWGN(latten_ae, snr)\n",
    "        features_hat = atten_ae.decoder(latten_ae)\n",
    "\n",
    "        pre = classifier(features_hat)\n",
    "\n",
    "        loss_AE = criterion_AE(features_hat, features_tea)\n",
    "        loss_CE = criterion_CE(pre, labels)\n",
    "        loss = loss_AE + loss_CE\n",
    "        \n",
    "        acc = (pre.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_cla.step()\n",
    "        optimizer_ae.step()\n",
    "        optimizer_stu.step()\n",
    "\n",
    "        batch_bar.set_postfix(loss=loss_AE.item(), acc=acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm  # 或者使用 from tqdm.auto import tqdm\n",
    "\n",
    "student.eval()\n",
    "classifier.eval()\n",
    "atten_ae.eval()\n",
    "channels = Channels(device)\n",
    "\n",
    "ACC_with_SNR = []\n",
    "\n",
    "# 外层进度条：遍历 SNR 值\n",
    "outer_bar = tqdm(range(-10, 25, 2), desc='Testing over SNR', ncols=120)\n",
    "for snr in outer_bar:\n",
    "    # 内层进度条：遍历 test_loader 的所有 batch\n",
    "    batch_bar = tqdm(test_loader, desc=f\"Testing on SNR: {snr}\", leave=False, ncols=120)\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for images, labels in batch_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = student(images)\n",
    "            features = atten_ae.encoder(features)\n",
    "            features_awgn = channels.AWGN(features, snr)\n",
    "            features_awgn = atten_ae.decoder(features_awgn)\n",
    "            logits = classifier(features_awgn)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            \n",
    "            total_correct += (preds == labels).float().sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "        \n",
    "        # 实时更新内层进度条显示信息\n",
    "        batch_bar.set_postfix({'Acc': total_correct / total_samples})\n",
    "    \n",
    "    # 计算当前 SNR 下的准确率，并更新外层进度条显示\n",
    "    acc = total_correct / total_samples\n",
    "    ACC_with_SNR.append(acc)\n",
    "    outer_bar.set_postfix({'SNR': snr, 'Acc': acc})\n",
    "\n",
    "print(ACC_with_SNR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
